{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PM_data(data_path):\n",
    "    PM_data = {}\n",
    "    data_name_lst = [name for name in os.listdir(data_path) if name.startswith('PM2.5')]\n",
    "    for name in data_name_lst:\n",
    "        a_df = pd.read_excel(os.path.join(data_path, name), sheet_name='PM2.5')\n",
    "        PM_data[name.split('_')[1]] = a_df\n",
    "    return PM_data\n",
    "\n",
    "def load_selected_PM_data(data_path, selected_data_name):\n",
    "    PM_data = {}\n",
    "    data_name_lst = selected_data_name\n",
    "    for name in data_name_lst:\n",
    "        a_df = pd.read_excel(os.path.join(data_path, name), sheet_name='PM2.5')\n",
    "        PM_data[name.split('_')[1]] = a_df\n",
    "    return PM_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_new_station(name_lst, data_path, selected_data_name):\n",
    "    updates = []\n",
    "    for idx in range(len(name_lst)-1):\n",
    "        a_update = []\n",
    "        df0 = pd.read_excel(os.path.join(data_path, selected_data_name[idx]), sheet_name='station_detail')['รหัสสถานี'].to_list()\n",
    "        df1 = pd.read_excel(os.path.join(data_path, selected_data_name[idx+1]), sheet_name='station_detail')['รหัสสถานี'].to_list()\n",
    "        for id_station in df1:\n",
    "            if id_station not in df0:\n",
    "                a_update.append(id_station)\n",
    "        updates.append(a_update)\n",
    "    return updates\n",
    "\n",
    "def check_station(ref_station, variable_station):\n",
    "    ref_columns = [1]*len(ref_station)\n",
    "    for idx, station_name in enumerate(ref_station):\n",
    "        if station_name not in variable_station:\n",
    "            ref_columns[idx] = 0\n",
    "    return ref_columns\n",
    "\n",
    "def Check_for_NonMissing(PM_data, print_progress=True):\n",
    "    check_dict = {}\n",
    "    num_dict = {}\n",
    "    for year, df in PM_data.items():\n",
    "        num_nan = np.sum(df.isna().sum())\n",
    "        if num_nan == 0:\n",
    "            check_dict[year] = True\n",
    "            num_dict[year] = num_nan\n",
    "        else:\n",
    "            check_dict[year] = False\n",
    "            num_dict[year] = num_nan\n",
    "    if print_progress:\n",
    "        for year, state in check_dict.items():\n",
    "            if state:\n",
    "                print(year, 'Num:', num_dict[year], 'Pass')\n",
    "            else:\n",
    "                print(year, 'Num:', num_dict[year], 'Failed')\n",
    "    return check_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def made_locate_station(ref_name, var_name_lst, data_path):\n",
    "    locate_lst = []\n",
    "    ref_station= pd.read_excel(os.path.join(data_path, ref_name), sheet_name='station_detail')['รหัสสถานี'].to_list()\n",
    "    for idx in range(len(var_name_lst)):\n",
    "        variable_station = pd.read_excel(os.path.join(data_path, var_name_lst[idx]), sheet_name='station_detail')['รหัสสถานี'].to_list()\n",
    "        locate_lst.append(check_station(ref_station, variable_station))\n",
    "    return np.array(locate_lst), ref_station\n",
    "\n",
    "def made_provide_station(selected_data_name, data_path):\n",
    "    df = pd.DataFrame(columns=['station_id', 'station_name'])\n",
    "    for file_name in selected_data_name:\n",
    "        station_detail = pd.read_excel(os.path.join(data_path, file_name), sheet_name='station_detail')\n",
    "        select_detail = station_detail.copy()[['รหัสสถานี', 'ชื่อสถานี']].rename(columns={'รหัสสถานี':'station_id', 'ชื่อสถานี':'station_name'})\n",
    "        df = pd.concat([df, select_detail], axis=0)\n",
    "        df['station_name'] = df['station_name'].apply(lambda x: x.split(' ')[-1])\n",
    "    df = df.drop_duplicates(subset=['station_id']).reset_index().drop(columns=['index'])\n",
    "    provide_uqe = np.unique(df['station_name'].to_numpy())\n",
    "    label_uqe = np.arange(provide_uqe.shape[0])\n",
    "    provide_dict = {provide_uqe[i]:label_uqe[i] for i in range(label_uqe.shape[0])}\n",
    "    df['label'] = df['station_name'].apply(lambda x: provide_dict[x])\n",
    "    return df\n",
    "\n",
    "def made_sector_station(selected_data_name, data_path, label_dict):\n",
    "    df = pd.DataFrame(columns=['station_id', 'station_name'])\n",
    "    for file_name in selected_data_name:\n",
    "        station_detail = pd.read_excel(os.path.join(data_path, file_name), sheet_name='station_detail')\n",
    "        select_detail = station_detail.copy()[['รหัสสถานี', 'ชื่อสถานี']].rename(columns={'รหัสสถานี':'station_id', 'ชื่อสถานี':'station_name'})\n",
    "        df = pd.concat([df, select_detail], axis=0)\n",
    "        df['station_name'] = df['station_name'].apply(lambda x: x.split(' ')[-1])\n",
    "    df = df.drop_duplicates(subset=['station_id']).reset_index().drop(columns=['index'])\n",
    "    df['label'] = df['station_name'].apply(lambda x: label_dict[x])\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sectors' label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meteorology_labeling():\n",
    "    NE = ' อำนาจเจริญ, บึงกาฬ, บุรีรัมย์, ชัยภูมิ, กาฬสินธุ์, ขอนแก่น, เลย, มหาสารคาม, มุกดาหาร, นครพนม, นครราชสีมา, หนองบัวลำภู, หนองคาย, ร้อยเอ็ด, สกลนคร, ศรีสะเกษ, สุรินทร์, อุบลราชธานี, อุดรธานี, ยโสธร'\n",
    "    N = ' เชียงใหม่, เชียงราย, ลำปาง, ลำพูน, แม่ฮ่องสอน, น่าน, พะเยา, แพร่, อุตรดิตถ์, ตาก, สุโขทัย, พิษณุโลก, พิจิตร, กำแพงเพชร, เพชรบูรณ์'\n",
    "    C = ' นครสวรรค์, อุทัยธานี, อ่างทอง, ชัยนาท, พระนครศรีอยุธยา, กทม., ลพบุรี, นครปฐม, นนทบุรี, ปทุมธานี, สมุทรปราการ, สมุทรสาคร, สมุทรสงคราม, สระบุรี, สิงห์บุรี, สุพรรณบุรี, กาญจนบุรี, ราชบุรี'\n",
    "    E = ' ฉะเชิงเทรา, จันทบุรี, ชลบุรี, ปราจีนบุรี, ระยอง, สระแก้ว, ตราด, นครนายก'\n",
    "    SW = ' กระบี่, พังงา, ภูเก็ต, ระนอง, สตูล, ตรัง'\n",
    "    SE = ' เพชรบุรี, ประจวบคีรีขันธ์, ประจวบคิรีขันธ์, ชุมพร, นครศรีธรรมราช, นราธิวาส, ปัตตานี, พัทลุง, สงขลา, สุราษฏร์ธานี, ยะลา'\n",
    "    Thai_sector = [NE, N, C, E, SE, SW]\n",
    "    Thai_dict = {f'{j}': ['จ.' + i.split(' ')[-1] if i.split(' ')[-1] != 'กทม.' else i.split(' ')[-1] for i in Thai_sector[j].split(',')] for j in range(len(Thai_sector))}\n",
    "    swap_Thai_dict = {provide:sector for sector in Thai_dict.keys() for provide in Thai_dict[sector]}\n",
    "    return swap_Thai_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill nan on each station by thier recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fill_NaN_YearRecord:\n",
    "\n",
    "    def __init__(self, data_path, selected_years):\n",
    "        self.data_path = data_path\n",
    "        self.selected_years = selected_years\n",
    "        files_name_lst = [name for name in os.listdir(self.data_path) if name.startswith('PM2.5')] # Format PM2.5_(year)_.xlsx\n",
    "        self.selected_files = []\n",
    "        for y in self.selected_years:\n",
    "            for f in files_name_lst:\n",
    "                if str(y) in f:\n",
    "                    self.selected_files.append(f)\n",
    "        self.ref_file = self.selected_files[-1]\n",
    "\n",
    "        # Define Parameters\n",
    "        self.save_name = 'FillByYears'\n",
    "\n",
    "        # Pre-Define Function Parameters\n",
    "        self.PM_data = None\n",
    "        self.establish_df = None \n",
    "        self.station_dict = None\n",
    "        self.new_PM_data = None\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_columns(dct):\n",
    "        for key, val in dct.items():\n",
    "            a = dct[key]\n",
    "            columns_lst = ['Date']\n",
    "            num_column = []\n",
    "            for col_name in a.columns:\n",
    "                try:\n",
    "                    num_column.append(int(col_name))\n",
    "                except Exception:\n",
    "                    continue\n",
    "            num_column = np.array(sorted(num_column)[::-1]).astype(str)\n",
    "            a = a[np.append(columns_lst, num_column)]\n",
    "            dct[key] = a\n",
    "        return dct\n",
    "    \n",
    "    @staticmethod\n",
    "    def fill_na_all_station(stations_dict):\n",
    "        new_stations_dict = {}\n",
    "        for key, df in stations_dict.items():\n",
    "            if df.shape[1] > 2:\n",
    "                for idx in range(1, len(df.columns)-1):\n",
    "                    df_year = df[df.columns[idx]]\n",
    "                    df_before_year = df[df_year.isna()][df.columns[idx+1:]]\n",
    "                    fill_value = df_before_year.sum(axis=1) / (~df_before_year.isna()).sum(axis=1)\n",
    "                    full_df_year = df_year.fillna(fill_value)\n",
    "                    df[df.columns[idx]] = full_df_year\n",
    "            new_stations_dict[key] = df\n",
    "        return new_stations_dict\n",
    "\n",
    "    def made_establish_df(self):\n",
    "        locate_lst, ref_station = made_locate_station(self.ref_file, self.selected_files, self.data_path)\n",
    "        df = pd.DataFrame(locate_lst, columns=ref_station)\n",
    "        df_year = pd.DataFrame(self.selected_years, columns=['years'])\n",
    "        df = df_year.join(df)\n",
    "        df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "        return df\n",
    "    \n",
    "    def match_year_station(self):\n",
    "        PM_data_work = self.PM_data.copy()\n",
    "        station_lst = self.establish_df.columns[1:]\n",
    "        stations_dict = {}\n",
    "        for idx_station, now_station in enumerate(station_lst):\n",
    "            year_station = self.establish_df['years'][self.establish_df[now_station] == 1].to_list()\n",
    "            merge_switch = 0\n",
    "            for a_year in year_station:\n",
    "                a_year_df = PM_data_work[f'{a_year}'][[now_station]].rename(columns={now_station:f'{a_year}'})\n",
    "                a_year_df['Date'] = PM_data_work[f'{a_year}']['Date'].apply(lambda x: datetime.strftime(x, '%m_%d'))\n",
    "                if merge_switch == 0:\n",
    "                    station_df = a_year_df\n",
    "                else:\n",
    "                    station_df = pd.merge(station_df, a_year_df, on='Date')\n",
    "                merge_switch += 1\n",
    "            stations_dict[now_station] = station_df\n",
    "        return stations_dict\n",
    "    \n",
    "    def convert_to_original_yearfill(self):\n",
    "        new_PM_data = {}\n",
    "        for year_key, year_df in self.PM_data.items():\n",
    "            uniform_df = pd.DataFrame({'Date': year_df['Date'].apply(lambda x: datetime.strftime(x, '%m_%d'))})\n",
    "            for station_key, station_df in self.station_dict.items():\n",
    "                if year_key in station_df.columns:\n",
    "                    station_in_year = station_df[['Date', year_key]].rename(columns={year_key:station_key}).drop_duplicates(subset=['Date'])\n",
    "                    uniform_df = pd.merge(uniform_df, station_in_year, on='Date')\n",
    "            uniform_df['Date'] = uniform_df['Date'].apply(lambda x: year_key + '_' + x)\n",
    "            new_PM_data[year_key] = uniform_df\n",
    "        return new_PM_data\n",
    "    \n",
    "    def save_to_csv(self, save_path):\n",
    "        for key, val in self.new_PM_data.items():\n",
    "            val.to_csv(os.path.join(save_path, f'{self.save_name}_{key}_.csv'), index=False)\n",
    "    \n",
    "    def main(self, PM_data=None, save_path=None):\n",
    "        if PM_data:\n",
    "            self.PM_data = PM_data\n",
    "        else:\n",
    "            self.PM_data = load_selected_PM_data(self.data_path, self.selected_files)\n",
    "        self.establish_df = self.made_establish_df()\n",
    "        self.station_dict = self.fill_na_all_station(self.sort_columns(self.match_year_station()))\n",
    "        self.new_PM_data = self.convert_to_original_yearfill()\n",
    "        if save_path:\n",
    "            self.save_to_csv(save_path=save_path)\n",
    "        return self.new_PM_data\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill nan on each station by thier labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fill_NaN_Label:\n",
    "    def __init__(self, data_path, selected_years, label_df):\n",
    "        self.data_path = data_path\n",
    "        self.selected_years = selected_years\n",
    "        self.label_df = label_df\n",
    "        files_name_lst = [name for name in os.listdir(self.data_path) if name.startswith('PM2.5')] # Format PM2.5_(year)_.xlsx\n",
    "        self.selected_files = []\n",
    "        for y in self.selected_years:\n",
    "            for f in files_name_lst:\n",
    "                if str(y) in f:\n",
    "                    self.selected_files.append(f)\n",
    "\n",
    "        # Define Parameters\n",
    "        self.new_PM_data = {}\n",
    "        self.save_name = 'FillByProvide'\n",
    "\n",
    "        # Pre-Define Function Parameters\n",
    "        self.PM_data = None      \n",
    "\n",
    "    @staticmethod\n",
    "    def fill_na_all_label(label_dict):\n",
    "        new_label_dict = {}\n",
    "        for id, df in label_dict.items():\n",
    "            if len(df.shape) > 1:\n",
    "                for station_id in df.columns:\n",
    "                    df_station = df[station_id].copy()\n",
    "                    idx_for_cal = df.columns.to_list().copy()\n",
    "                    idx_for_cal.pop(idx_for_cal.index(station_id))\n",
    "                    fill_value = df[df_station.isna()][idx_for_cal].mean(axis=1)\n",
    "                    full_df_station = df_station.fillna(fill_value)\n",
    "                    df[station_id] = full_df_station\n",
    "            new_label_dict[id] = df\n",
    "        return new_label_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_to_original_labelfill(label_dict):\n",
    "        new_df = label_dict['Date']\n",
    "        for name_col in list(label_dict.keys())[1:]:\n",
    "            new_df = pd.concat([new_df, label_dict[name_col]], axis=1)\n",
    "        return new_df\n",
    "    \n",
    "    def match_label_station(self, PM_data_year):\n",
    "        label_dict = {'Date':PM_data_year['Date']}\n",
    "        station_columns = PM_data_year.columns[1:]\n",
    "        for station_id in station_columns:\n",
    "            the_label = self.label_df['label'][self.label_df['station_id'] == station_id].to_list()[0]\n",
    "            if str(the_label) not in label_dict.keys():\n",
    "                label_dict[str(the_label)] = PM_data_year[station_id]\n",
    "            else:\n",
    "                label_dict[str(the_label)] = pd.concat([label_dict[str(the_label)], PM_data_year[station_id]], axis=1)\n",
    "        return label_dict\n",
    "\n",
    "    def save_to_csv(self, save_path):\n",
    "        for key, val in self.new_PM_data.items():\n",
    "            val.to_csv(os.path.join(save_path, f'{self.save_name}_{key}_.csv'), index=False)   \n",
    "\n",
    "    def main(self, PM_data=None, save_path=None):\n",
    "        if PM_data:\n",
    "            self.PM_data = PM_data\n",
    "        else:\n",
    "            self.PM_data = load_selected_PM_data(self.data_path, self.selected_files)\n",
    "        for a_year, PM_data_year in self.PM_data.items():\n",
    "            label_dict = self.match_label_station(PM_data_year)\n",
    "            new_label_dict = self.fill_na_all_label(label_dict)\n",
    "            self.new_PM_data[a_year] = self.convert_to_original_labelfill(new_label_dict)\n",
    "        if save_path:\n",
    "            self.save_to_csv(save_path)\n",
    "        return self.new_PM_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill nan on each station by interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fill_NaN_Interpolation:\n",
    "    def __init__(self, data_path, selected_years):\n",
    "        self.data_path = data_path\n",
    "        self.selected_years = selected_years\n",
    "        files_name_lst = [name for name in os.listdir(self.data_path) if name.startswith('PM2.5')] # Format PM2.5_(year)_.xlsx\n",
    "        self.selected_files = []\n",
    "        for y in self.selected_years:\n",
    "            for f in files_name_lst:\n",
    "                if str(y) in f:\n",
    "                    self.selected_files.append(f)\n",
    "\n",
    "        # Define Parameters\n",
    "        self.inter_method = 'spline'\n",
    "        self.order = 2\n",
    "        self.new_PM_data = {}\n",
    "        self.save_name = 'FillByInterpolation'\n",
    "        self.print_progess = False\n",
    "\n",
    "        # Pre-Define Function Parameters\n",
    "        self.PM_data = None   \n",
    "\n",
    "    def Interpolate_df(self, check_dict):\n",
    "        new_PM_data = {}\n",
    "        PM_keys = list(self.PM_data.keys())\n",
    "        for idx in range(len(PM_keys)):\n",
    "            if check_dict[PM_keys[idx]]:\n",
    "                new_PM_data[PM_keys[idx]] = self.PM_data[PM_keys[idx]]\n",
    "            else:\n",
    "                if self.inter_method in ['spline', 'polynomial']:\n",
    "                    new_PM_data[PM_keys[idx]] = self.PM_data[PM_keys[idx]].interpolate(self.inter_method, order=self.order)\n",
    "                else:\n",
    "                    new_PM_data[PM_keys[idx]] = self.PM_data[PM_keys[idx]].interpolate(self.inter_method)\n",
    "        return new_PM_data\n",
    "    \n",
    "    def save_to_csv(self, save_path):\n",
    "        for key, val in self.new_PM_data.items():\n",
    "            val.to_csv(os.path.join(save_path, f'{self.save_name}_{key}_.csv'), index=False)\n",
    "            # val.to_excel(os.path.join(save_path, f'{self.save_name}_{key}_.xlsx'), index=False)  \n",
    "    \n",
    "    def main(self, PM_data=None, save_path=None):\n",
    "        if PM_data:\n",
    "            self.PM_data = PM_data\n",
    "        else:\n",
    "            self.PM_data = load_selected_PM_data(self.data_path, self.selected_files)\n",
    "        if self.print_progess:\n",
    "            print('--------Before interpolating--------')\n",
    "            check_dict = Check_for_NonMissing(self.PM_data)\n",
    "            print('-------------------------------------')\n",
    "            self.new_PM_data = self.Interpolate_df(check_dict)\n",
    "            print('--------After interpolating--------')\n",
    "            check_dict = Check_for_NonMissing(self.new_PM_data)\n",
    "            print('-------------------------------------')\n",
    "        else:\n",
    "            check_dict = Check_for_NonMissing(self.PM_data, self.print_progess)\n",
    "            self.new_PM_data = self.Interpolate_df(check_dict)\n",
    "        if save_path:\n",
    "            self.save_to_csv(save_path)\n",
    "        return self.new_PM_data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
