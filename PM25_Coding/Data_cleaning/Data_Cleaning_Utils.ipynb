{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PM_data(data_path):\n",
    "    PM_data = {}\n",
    "    data_name_lst = [name for name in os.listdir(data_path) if name.startswith('PM2.5')]\n",
    "    for name in data_name_lst:\n",
    "        a_df = pd.read_excel(os.path.join(data_path, name), sheet_name='PM2.5')\n",
    "        PM_data[name.split('_')[1]] = a_df\n",
    "    return PM_data\n",
    "\n",
    "def load_selected_PM_data(data_path, selected_data_name):\n",
    "    PM_data = {}\n",
    "    data_name_lst = selected_data_name\n",
    "    for name in data_name_lst:\n",
    "        a_df = pd.read_excel(os.path.join(data_path, name), sheet_name='PM2.5')\n",
    "        PM_data[name.split('_')[1]] = a_df\n",
    "    return PM_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_new_station(name_lst, data_path, selected_data_name):\n",
    "    updates = []\n",
    "    for idx in range(len(name_lst)-1):\n",
    "        a_update = []\n",
    "        df0 = pd.read_excel(os.path.join(data_path, selected_data_name[idx]), sheet_name='station_detail')['รหัสสถานี'].to_list()\n",
    "        df1 = pd.read_excel(os.path.join(data_path, selected_data_name[idx+1]), sheet_name='station_detail')['รหัสสถานี'].to_list()\n",
    "        for id_station in df1:\n",
    "            if id_station not in df0:\n",
    "                a_update.append(id_station)\n",
    "        updates.append(a_update)\n",
    "    return updates\n",
    "\n",
    "def check_station(ref_station, variable_station):\n",
    "    ref_columns = [1]*len(ref_station)\n",
    "    for idx, station_name in enumerate(ref_station):\n",
    "        if station_name not in variable_station:\n",
    "            ref_columns[idx] = 0\n",
    "    return ref_columns\n",
    "\n",
    "def made_locate_station(ref_name, var_name_lst, data_path):\n",
    "    locate_lst = []\n",
    "    ref_station= pd.read_excel(os.path.join(data_path, ref_name), sheet_name='station_detail')['รหัสสถานี'].to_list()\n",
    "    for idx in range(len(var_name_lst)):\n",
    "        variable_station = pd.read_excel(os.path.join(data_path, var_name_lst[idx]), sheet_name='station_detail')['รหัสสถานี'].to_list()\n",
    "        locate_lst.append(check_station(ref_station, variable_station))\n",
    "    return np.array(locate_lst), ref_station"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill nan on each station by thier recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fill_NaN_YearRecord:\n",
    "\n",
    "    def __init__(self, data_path, selected_years):\n",
    "        self.data_path = data_path\n",
    "        self.selected_years = selected_years\n",
    "        files_name_lst = [name for name in os.listdir(self.data_path) if name.startswith('PM2.5')] # Format PM2.5_(year)_.xlsx\n",
    "        self.selected_files = []\n",
    "        for y in self.selected_years:\n",
    "            for f in files_name_lst:\n",
    "                if str(y) in f:\n",
    "                    self.selected_files.append(f)\n",
    "        self.ref_file = self.selected_files[-1]\n",
    "\n",
    "        # Define Parameters\n",
    "        self.save_name = 'fill_by_years'\n",
    "\n",
    "        # Pre-Define Function Parameters\n",
    "        self.PM_data = None\n",
    "        self.establish_df = None \n",
    "        self.station_dict = None\n",
    "        self.new_PM_data = None\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_columns(dct):\n",
    "        for key, val in dct.items():\n",
    "            a = dct[key]\n",
    "            columns_lst = ['Date']\n",
    "            num_column = []\n",
    "            for col_name in a.columns:\n",
    "                try:\n",
    "                    num_column.append(int(col_name))\n",
    "                except Exception:\n",
    "                    continue\n",
    "            num_column = np.array(sorted(num_column)[::-1]).astype(str)\n",
    "            a = a[np.append(columns_lst, num_column)]\n",
    "            dct[key] = a\n",
    "        return dct\n",
    "    \n",
    "    @staticmethod\n",
    "    def fill_na_all_station(stations_dict):\n",
    "        new_stations_dict = {}\n",
    "        for key, df in stations_dict.items():\n",
    "            if df.shape[1] > 2:\n",
    "                for idx in range(1, len(df.columns)-1):\n",
    "                    df_year = df[df.columns[idx]]\n",
    "                    df_before_year = df[df_year.isna()][df.columns[idx+1:]]\n",
    "                    fill_value = df_before_year.sum(axis=1) / (~df_before_year.isna()).sum(axis=1)\n",
    "                    full_df_year = df_year.fillna(fill_value)\n",
    "                    df[df.columns[idx]] = full_df_year\n",
    "            new_stations_dict[key] = df\n",
    "        return new_stations_dict\n",
    "\n",
    "    def made_establish_df(self):\n",
    "        locate_lst, ref_station = made_locate_station(self.ref_file, self.selected_files, self.data_path)\n",
    "        df = pd.DataFrame(locate_lst, columns=ref_station)\n",
    "        df_year = pd.DataFrame(self.selected_years, columns=['years'])\n",
    "        df = df_year.join(df)\n",
    "        df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "        return df\n",
    "    \n",
    "    def match_year_station(self):\n",
    "        PM_data_work = self.PM_data.copy()\n",
    "        station_lst = self.establish_df.columns[1:]\n",
    "        stations_dict = {}\n",
    "        for idx_station, now_station in enumerate(station_lst):\n",
    "            year_station = self.establish_df['years'][self.establish_df[now_station] == 1].to_list()\n",
    "            merge_switch = 0\n",
    "            for a_year in year_station:\n",
    "                a_year_df = PM_data_work[f'{a_year}'][[now_station]].rename(columns={now_station:f'{a_year}'})\n",
    "                a_year_df['Date'] = PM_data_work[f'{a_year}']['Date'].apply(lambda x: datetime.strftime(x, '%m_%d'))\n",
    "                if merge_switch == 0:\n",
    "                    station_df = a_year_df\n",
    "                else:\n",
    "                    station_df = pd.merge(station_df, a_year_df, on='Date')\n",
    "                merge_switch += 1\n",
    "            stations_dict[now_station] = station_df\n",
    "        return stations_dict\n",
    "    \n",
    "    def convert_to_original_yearfill(self):\n",
    "        new_PM_data = {}\n",
    "        for year_key, year_df in self.PM_data.items():\n",
    "            print('Current :', year_key)\n",
    "            uniform_df = pd.DataFrame({'Date': year_df['Date'].apply(lambda x: datetime.strftime(x, '%m_%d'))})\n",
    "            for station_key, station_df in self.station_dict.items():\n",
    "                if year_key in station_df.columns:\n",
    "                    station_in_year = station_df[['Date', year_key]].rename(columns={year_key:station_key}).drop_duplicates(subset=['Date'])\n",
    "                    uniform_df = pd.merge(uniform_df, station_in_year, on='Date')\n",
    "            new_PM_data[year_key] = uniform_df\n",
    "        return new_PM_data\n",
    "    \n",
    "    def save_to_csv(self, save_path):\n",
    "        for key, val in self.new_PM_data.items():\n",
    "            val['Date'] = val['Date'].apply(lambda x: key + '_' + x)\n",
    "            val.to_csv(os.path.join(save_path, f'{self.save_name}.{key}.csv'), index=False)\n",
    "    \n",
    "    def main(self, save_path=None):\n",
    "        self.PM_data = load_selected_PM_data(self.data_path, self.selected_files)\n",
    "        self.establish_df = self.made_establish_df()\n",
    "        # print(self.establish_df)\n",
    "        self.station_dict = self.fill_na_all_station(self.sort_columns(self.match_year_station()))\n",
    "        self.new_PM_data = self.convert_to_original_yearfill()\n",
    "        if save_path:\n",
    "            self.save_to_csv(save_path=save_path)\n",
    "        return self.new_PM_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
