{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.PM_path = './PM_Data/'\n",
    "        self.Rain_path = './Rain_Data/'\n",
    "        self.PM_startswith = 'FillByAll'\n",
    "        self.Rain_startswith = 'Meteo'\n",
    "\n",
    "    def load_PM_data(self):\n",
    "        PM_data = {name.split('_')[1]:pd.read_csv(os.path.join(self.PM_path, name)) for name in os.listdir(self.PM_path) if name.startswith(self.PM_startswith)}\n",
    "        return PM_data\n",
    "\n",
    "    def load_Rain_data(self):\n",
    "        Rain_data = {name.split('_')[1]:pd.read_excel(os.path.join(self.Rain_path, name)) for name in os.listdir(self.Rain_path) if name.startswith(self.Rain_startswith)}\n",
    "        return Rain_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_data_TS(PM_data, staion_id, scope_year=None): # scope_year = [2017, 2018, 2019]\n",
    "    if scope_year:\n",
    "        new_PM_data = {a_year:year_df for a_year, year_df in PM_data.items() if int(a_year) in scope_year}\n",
    "    else:\n",
    "        new_PM_data = PM_data.copy()\n",
    "    staion_TS = []\n",
    "    for val in new_PM_data.values():\n",
    "        if staion_id in val.columns:\n",
    "            staion_at_year = val[['Date', staion_id]].copy()\n",
    "            staion_at_year['Date'] = pd.to_datetime(staion_at_year['Date'].copy(), format='%Y_%m_%d')\n",
    "            staion_TS.append(staion_at_year.set_index(['Date']).rename(columns={staion_id:'PM_'+staion_id}))\n",
    "    return pd.concat(staion_TS, axis=0)\n",
    "\n",
    "def window_input(window_length: int, data: pd.DataFrame, column_name: str): \n",
    "    df = data.copy()\n",
    "    add_columns = [column_name]\n",
    "    i = 1\n",
    "    while i < window_length:\n",
    "        df[f'{column_name}_{i}'] = df[column_name].shift(-i)\n",
    "        add_columns.append(f'{column_name}_{i}')\n",
    "        i = i + 1   \n",
    "    # Fill NaN with zero\n",
    "    df = df.fillna(0)\n",
    "    return df, add_columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_piplines(window_length, data, column_name, target_name, portion, model):\n",
    "    # preparing data\n",
    "    new_data, add_columns = window_input(window_length, data.copy(), column_name)\n",
    "    X, y = new_data.copy()[add_columns].to_numpy(), new_data.copy()[target_name].to_numpy()\n",
    "    dim = len(add_columns)\n",
    "    minmax_model = MinMaxScaler().fit(X)\n",
    "    X = minmax_model.transform(X)\n",
    "    X_train, X_test = X[:int(X.shape[0] * portion)].reshape(-1, dim), X[int(X.shape[0] * portion):].reshape(-1, dim)\n",
    "    y_train, y_test = y[:int(y.shape[0] * portion)].reshape(-1, 1), y[int(y.shape[0] * portion):].reshape(-1, 1)\n",
    "\n",
    "    # train model\n",
    "    trained_model = model.fit(X_train, y_train.ravel())\n",
    "    return trained_model, minmax_model, X_test, y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_piplines(window_length, data, column_lst, target_name, portion, model):\n",
    "    # preparing data\n",
    "    new_data = data.copy()\n",
    "    add_columns = []\n",
    "    for column_name in column_lst:\n",
    "        new_data, new_columns = window_input(window_length, new_data, column_name)\n",
    "        add_columns.extend(new_columns)\n",
    "    X, y = new_data.copy()[add_columns].to_numpy(), new_data.copy()[target_name].to_numpy()\n",
    "    dim = len(add_columns)\n",
    "    minmax_model = MinMaxScaler().fit(X)\n",
    "    X = minmax_model.transform(X)\n",
    "    X_train, X_test = X[:int(X.shape[0] * portion)].reshape(-1, dim), X[int(X.shape[0] * portion):].reshape(-1, dim)\n",
    "    y_train, y_test = y[:int(y.shape[0] * portion)].reshape(-1, 1), y[int(y.shape[0] * portion):].reshape(-1, 1)\n",
    "\n",
    "    # train model\n",
    "    trained_model = model.fit(X_train, y_train.ravel())\n",
    "    return trained_model, minmax_model, X_test, y_test.ravel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression(X_train, y_train, X_test, y_test, model_path):\n",
    "    regrssor = pickle.load(open(model_path, 'rb'))\n",
    "    y_pred_test = regrssor.predict(X_test)\n",
    "    y_pred_train = regrssor.predict(X_train)\n",
    "    # Train fitting\n",
    "    if X_train.shape[1] > 1:\n",
    "        for i in range(X_train.shape[1]):\n",
    "            plt.plot(X_train[:, i], y_pred_train, '.', label='Prediction')\n",
    "            plt.plot(X_train[:, i], y_train, '.', label='Actual')\n",
    "            plt.ylabel('PM 2.5')\n",
    "            plt.xlabel('Rain volume')\n",
    "            plt.title(f'Input: {regrssor.domain[i].name}')\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.pause(0.0001)\n",
    "            plt.clf()\n",
    "    else:\n",
    "        plt.plot(X_train[:, 0], y_pred_train, '.', label='Prediction')\n",
    "        plt.plot(X_train[:, 0], y_train, '.', label='Actual')\n",
    "        plt.ylabel('PM 2.5')\n",
    "        plt.xlabel('Rain volume')\n",
    "        plt.title(f'Input: {regrssor.domain[0].name}')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        \n",
    "  \n",
    "    \n",
    "    plt.figure()\n",
    "    if X_test.shape[1] > 1:\n",
    "        for i in range(X_test.shape[1]):\n",
    "            plt.plot(X_test[:, i], y_pred_test, '.', label='Prediction')\n",
    "            plt.plot(X_test[:, i], y_test, '.', label='Actual')\n",
    "            plt.ylabel('PM 2.5')\n",
    "            plt.xlabel('Rain volume')\n",
    "            plt.title(f'Input: {regrssor.domain[i].name}')\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.pause(0.0001)\n",
    "            plt.clf()\n",
    "    \n",
    "    else:\n",
    "        plt.plot(X_test[:, 0], y_pred_test, '.', label='Prediction')\n",
    "        plt.plot(X_test[:, 0], y_test, '.', label='Actual')\n",
    "        plt.ylabel('PM 2.5')\n",
    "        plt.xlabel('Rain volume')\n",
    "        plt.title(f'Input: {regrssor.domain[0].name}')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation_Model(model_dict, X_test, y_test):\n",
    "    for model_name, model in model_dict.items():\n",
    "        print(f'Model {model_name}')\n",
    "        y_pred = model.predict(X_test)\n",
    "        SS_Residual = sum((y_test-y_pred)**2)       \n",
    "        SS_Total = sum((y_test-np.mean(y_pred))**2)     \n",
    "        r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "        print(SS_Residual, SS_Total)\n",
    "        print(len(y_test), X_test.shape[1])\n",
    "        adjusted_r_squared = 1 - (1-r_squared)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "        # The mean squared error\n",
    "        print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "        # The coefficient of determination: 1 is perfect prediction\n",
    "        print(\"Coefficient of determination or R2-score: %.2f\" % r2_score(y_test, y_pred))\n",
    "        print('R square:', r_squared)\n",
    "        print('Adjusted R square:', adjusted_r_squared)\n",
    "        print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
